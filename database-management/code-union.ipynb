{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword sentiment analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# countries\n",
    "\n",
    "select avg(postive_score), avg(negative_score)\n",
    "    from abroad\n",
    "        where content like '%美國%';\n",
    "\n",
    "# cram schools\n",
    "\n",
    "select avg(postive_score), avg(negative_score)\n",
    "    from abroad\n",
    "        where content like '%SK2%';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install packages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# download package if needed\n",
    "!pip install pandas numpy pprint pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "import pyodbc\n",
    "\n",
    "print( [x for x in pyodbc.drivers() if x.startswith('Microsoft Access Driver')] )\n",
    "\n",
    "conn_str = (\n",
    "    r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "    r'DBQ=./留學.accdb;'\n",
    "    )\n",
    "\n",
    "# built connection\n",
    "cnxn = pyodbc.connect(conn_str)\n",
    "# cursor: the \"mouse\" in a connection\n",
    "crsr = cnxn.cursor()\n",
    "\n",
    "# if you do anything with the DB, remember to commit\n",
    "\n",
    "for table_info in crsr.tables(tableType='TABLE'):\n",
    "    print(table_info.table_name)\n",
    "    \n",
    "print(crsr.description)\n",
    "\n",
    "# execute command with the crusor\n",
    "\n",
    "crsr.execute('SELECT * from ts_page_content')\n",
    "rows = crsr.fetchall()\n",
    "    \n",
    "crsr.close()\n",
    "cnxn.close()\n",
    "\n",
    "texts = np.array(rows)[:,-6]\n",
    "\n",
    "# load model\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "ner = NER(\"./data\" ) #, disable_cuda=False)\n",
    "\n",
    "# build word segment output\n",
    "\n",
    "sent_list = ws ( texts )\n",
    "pos_list  = pos( sent_list )\n",
    "\n",
    "# save word-segment output\n",
    "# pickle a variable to a file\n",
    "file = open('sentence_list.pickle', 'wb')\n",
    "pickle.dump(sent_list, file)\n",
    "file.close()\n",
    "\n",
    "# get ner output\n",
    "\n",
    "ner_list = []\n",
    "error_list = []\n",
    "\n",
    "for i in range(len(sent_list)):\n",
    "    \n",
    "    try:\n",
    "        ner_tmp = ner(sent_list[i: i+1], pos_list[i: i+1])\n",
    "        ner_list += ner_tmp\n",
    "        print(i, 'is done!')\n",
    "\n",
    "    except AssertionError:\n",
    "        error_list.append( i )\n",
    "        print(i, 'has encoding issue, thus raise assertion error!')\n",
    "\n",
    "\n",
    "file = open('NER_list.pickle', 'wb')\n",
    "pickle.dump(ner_list, file)\n",
    "file.close()\n",
    "\n",
    "print(error_list, 'are excluded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top-N popular named entity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if wondering the M most popular name in t type of entity, use this cell\n",
    "# entity types: see above\n",
    "\n",
    "M = int(input('top M popular entity, M ='))\n",
    "t = input('which type of entity? ')\n",
    "\n",
    "count_dict = Counter( df[df['type'] == t].iloc[:,2] )\n",
    "\n",
    "count_df = sorted( count_dict, key=lambda x: count_dict[x], reverse=True)[:M]\n",
    "\n",
    "count_df = pd.DataFrame( [ (i, count_dict[i]) for i in count_df ] )\n",
    "count_df.to_csv('top' + str(M) + '-pop-' + t + '.csv', index=False, header=[t, 'counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### co-occurrence analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# read pre-trained NER data\n",
    "\n",
    "df = pd.read_csv('./NER_study_abroad.csv')\n",
    "\n",
    "with open('./NER_list_1-20000.pickle', 'rb') as file:\n",
    "    enr_list1 = pickle.load( file )\n",
    "    file.close()\n",
    "\n",
    "with open('./NER_list_20001-40000.pickle', 'rb') as file:\n",
    "    enr_list2 = pickle.load( file )\n",
    "    file.close()\n",
    "\n",
    "with open('./NER_list_40000-.pickle', 'rb') as file:\n",
    "    enr_list3 = pickle.load( file )\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "enr_list = enr_list1 + enr_list2 + enr_list3\n",
    "\n",
    "co_ocurr = []\n",
    "\n",
    "\n",
    "# get entity that relevent\n",
    "# as for the entity code meaning, see: https://wiki.planetoid.info/index.php/Named_entity_recognition_tools\n",
    "\n",
    "for e in enr_list:\n",
    "    \n",
    "    lst = []\n",
    "    \n",
    "    for i in e:\n",
    "        # add code if needed\n",
    "        if i[2] in ['ORG', 'GPE', 'NORP', 'FAC', 'LOC']:\n",
    "            lst.append(i[3])\n",
    "            \n",
    "    if lst != []:\n",
    "        co_ocurr.append(lst)\n",
    "        \n",
    "        \n",
    "tmp = []\n",
    "for i in co_ocurr:\n",
    "    tmp += i\n",
    "    \n",
    "types = list(set(tmp))\n",
    "\n",
    "N = len(types)\n",
    "matrix = { i:{} for i in types }\n",
    "\n",
    "\n",
    "# build co-occurence dictionary\n",
    "\n",
    "for i in co_ocurr:\n",
    "#     print(i)\n",
    "    if len(i) > 1:\n",
    "        comb = [j for j in combinations(i, 2)]\n",
    "        for item in comb:\n",
    "            \n",
    "            # count co-occurrence\n",
    "            if item[1] in matrix[item[0]]: # key, dict\n",
    "                matrix[item[0]][item[1]] += 1\n",
    "            else:\n",
    "                matrix[item[0]][item[1]] = 1\n",
    "                \n",
    "            if item[0] in matrix[item[1]]: # key, dict\n",
    "                matrix[item[1]][item[0]] += 1\n",
    "            else:\n",
    "                matrix[item[1]][item[0]] = 1\n",
    "                \n",
    "sort_keys = sorted(matrix, key=lambda x: len(matrix[x]), reverse=True)\n",
    "\n",
    "# print entity names\n",
    "\n",
    "print('Entity List:')\n",
    "pprint(sort_keys)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "while True:\n",
    "    query = input('type \"stop\" to break, or enter the entity name: ')\n",
    "\n",
    "    if query == 'stop':\n",
    "        print('thanks for watching!')\n",
    "        break\n",
    "\n",
    "    tmp = [(i, matrix[query][i]) for i in sorted( matrix[query], key=lambda x: matrix[query][x], reverse=True )]\n",
    "    pd.DataFrame( tmp ).to_csv( query + '.csv', index=False, header=False )\n",
    "    pprint( tmp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### co-occurrence analysis on specific words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reload a file to a variable\n",
    "with open('sentence_list.pickle', 'rb') as file:\n",
    "    sent_list = pickle.load( file )\n",
    "    file.close()\n",
    "    \n",
    "# print(len(sent_list))\n",
    "# len(enr_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "first_query  = input('first query, seperate values with space: ').split()\n",
    "second_query = input('second query, seperate values with space: ').split()\n",
    "\n",
    "first_outcome  = []\n",
    "second_outcome = {}\n",
    " \n",
    "for i in sent_list:\n",
    "    count = 0\n",
    "    for keyword in first_query:\n",
    "        if keyword in i:\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        first_outcome.append(i)\n",
    "        \n",
    "print()\n",
    "print('Simple Statistics: ')\n",
    "print('In the articles that contains', first_query )\n",
    "print('the number of articles contain second query are...')\n",
    "for key in second_query:\n",
    "    lst = [i for i in first_outcome if key in i]\n",
    "    second_outcome[key] = lst\n",
    "    print( key, len(lst) )\n",
    "    \n",
    "with open('output.txt', 'w', encoding='utf-8') as f:\n",
    "    print(second_outcome, file=f)\n",
    "    f.close()\n",
    "    \n",
    "print()\n",
    "print('the nested output is sent to output.txt')\n",
    "\n",
    "\n",
    "# readable output\n",
    "\n",
    "second_outcome_readable = { key: [''.join(i) for i in second_outcome[key]] for key in second_outcome }\n",
    "with open('output_whole_sentence.txt', 'w', encoding='utf-8') as f:\n",
    "    pprint(second_outcome_readable, f)\n",
    "    f.close()\n",
    "    \n",
    "print()\n",
    "print('the readable nested output is sent to output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trend  analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def trends(keys, col='content'):\n",
    "        \n",
    "    # if only one keyword as string, convert to list type\n",
    "    if type(keys) == str:\n",
    "        keys = [keys]\n",
    "\n",
    "    # counts keyword occurrence by month\n",
    "    df = db[['post_time', col]]\n",
    "    counts = [] # to contain counts of each word in each month\n",
    "    for g, data in df.groupby(df['post_time'].dt.month):\n",
    "        c = []  # temp list for each word\n",
    "        for word in keys:\n",
    "            c.append(data[col].str.count(word).sum())\n",
    "        counts.append(c)    # append monthly data of each word to counts\n",
    "    \n",
    "    # convert to relative trend\n",
    "    counts = np.array(counts)   # convert counts to np.array type\n",
    "    hottest = np.max(counts)\n",
    "    trend = counts / hottest * 100\n",
    "    \n",
    "    # plot on graph\n",
    "    months = sorted(db['post_time'].dt.month.unique())\n",
    "    lines = []  # to contain each line \n",
    "    for t in range(trend.shape[1]):\n",
    "        lines.append(plt.plot(months, trend[:, t], '-o'))\n",
    "    \n",
    "    # format graph\n",
    "    plt.xticks(months, months)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.grid(axis='y', color='#d9d9d9')\n",
    "    if len(lines) != 1: # only show when there're multiple keywords\n",
    "        plt.legend([l[0] for l in lines], ['#{:d}'.format(n+1) for n in range(len(keys))])\n",
    "        print(['#{:d}: {}'.format(n+1, keys[n]) for n in range(len(keys))])\n",
    "    plt.xlabel('Months')\n",
    "    plt.ylabel('Index (100 = {:d} times mentioned)'.format(hottest))\n",
    "\t#plt.ylabel('Index (100 = {:d} times mentioned)'.format(hottest))\n",
    "    \n",
    "    #plt.title('Popularity of \"{}\"'.format(keys)) \n",
    "    plt.show()\n",
    "    \n",
    "trends('代辦')\n",
    "trends(['GMAT', 'GRE'])\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword sentiment analysis - visualization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  matplotlib as mpl\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "# read in data\n",
    "path = r'D:\\Brian\\大學生活\\108-1大四上\\Database Management\\Assignments\\HW5\\2019_social_corpus'\n",
    "db = pd.read_csv(path + r'\\db_study_abroad.txt', sep=',', low_memory=False)\n",
    "\n",
    "def sentiment_analysis(category):\n",
    "    # initialize an array to contain index and scores\n",
    "    scores = np.empty([4, len(category)]) \n",
    "\n",
    "    # function to return the mean sentiment score of a key word\n",
    "    def meanSent(word, sentiment):\n",
    "        return db[db['content'].str.contains(word)][sentiment].mean()\n",
    "    # or more rigorously,\n",
    "    def meanSent_keyOnly(word, word_list, sentiment):\n",
    "        mask = db['content'].str.contains(word)    # wanted\n",
    "        for c in word_list:   # unwanted\n",
    "            if c != word:\n",
    "                mask = mask & ~db['content'].str.contains(c)\n",
    "        return db[mask][sentiment].mean()\n",
    "\n",
    "    # index\n",
    "    scores[0,:] = [i+1 for i in range(len(category))]\n",
    "\n",
    "    # positive scores\n",
    "    scores[1,:] = [meanSent(c, 'positive_score') for c in category]\n",
    "\n",
    "    # negative scores\n",
    "    scores[2,:] = [meanSent(c, 'negative_score')*-1 for c in category]\n",
    "\n",
    "    # count occurence \n",
    "    scores[3,:] = [len(db[db['content'].str.contains(c)]) for c in category]\n",
    "\n",
    "    # plot bars\n",
    "    plt.bar(scores[0,:]-.2, scores[1,:], width=.4)  # positive scores\n",
    "    plt.bar(scores[0,:]+.2, scores[2,:], width=.4)  # negative scores\n",
    "\n",
    "    # formatting\n",
    "    plt.xticks(scores[0,:], ['#{:.0f}\\n{:.0f}'.format(scores[0,n], scores[3,n]) for n in range(len(category))])\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Number & Mentioned Times')\n",
    "    for c in range(len(category)):\n",
    "        plt.text(scores[0,c]-.2, scores[1,c]+plt.ylim()[1]*.02, '{:.2f}'.format(scores[1,c]), ha='center')\n",
    "        plt.text(scores[0,c]+.2, scores[2,c]+plt.ylim()[0]*.1, '{:.2f}'.format(scores[2,c]), ha='center')\n",
    "    plt.grid(axis='y', color='#d9d9d9')\n",
    "    plt.gca().set_axisbelow(True)\n",
    "\n",
    "    # show label\n",
    "    print(['#{:.0f}: {}'.format(scores[0, n], category[n]) for n in range(len(category))])\n",
    "\n",
    "    # show plot\n",
    "    plt.show()\n",
    "\n",
    "sentiment_analysis(['SK2', '字神', 'Mason', '菁英', '美加', '戴爾'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### potential customer analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X1214 <- read_excel(\"D:/大學/2019_social_corpus/1214.xlsx\")\n",
    "sp <- strsplit(X1214$author, \"大學\")\n",
    "sp2 <- lapply(seq(length(sp)), function(i) strsplit(sp[[i]][2], \"/\"))\n",
    "\n",
    "school <- c()\n",
    "major <- c()\n",
    "gender <- c()\n",
    "for(i in seq(length(sp2))){\n",
    "  school[i] <- paste0(sp[[i]][1], \"大學\")\n",
    "  major[i] <- sp2[[i]][[1]][1]\n",
    "  gender[i] <- sp2[[i]][[1]][2]\n",
    "}\n",
    "major[major %in% \"\"] <- NA\n",
    "summary(factor(major))[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mg <- na.omit(data.frame(school = school, major = major, gender = gender, stringsAsFactors = F))\n",
    "res <- summary(factor(major))\n",
    "mgtop <- mg[mg$major %in% names(res[1:10]), ]\n",
    "\n",
    "ggplot(mgtop, aes(x =  reorder(major, major, function(x) -length(x)), fill = gender)) + \n",
    "  geom_bar(width = 0.5, position = \"stack\") +\n",
    "  labs(x = \"major\", y = \"count\")\n",
    "\n",
    "mgstrange <- mg[mg$major %in% c(\"民航研究所\", \"聖塔芭芭拉分校電影與媒體\"), ]\n",
    "unique(mgstrange)\n",
    "\n",
    "mgtop2 <- mg[mg$major %in% names(res[c(2,4:9, 12:14)]), ]\n",
    "\n",
    "ggplot(mgtop2, aes(x =  reorder(major, major, function(x) -length(x)), fill = gender)) + \n",
    "  geom_bar(width = 0.5, position = \"stack\") +\n",
    "  labs(x = \"major\", y = \"count\")\n",
    "\n",
    "ForeignLanguages <- sum(grepl(\"英語\", mg$major), grepl(\"英文\", mg$major), grepl(\"英國語文\", mg$major), grepl(\"外文\", mg$major), grepl(\"外語\", mg$major), grepl(\"外國語文\", mg$major)) # 外文相關科系\n",
    "EE <- sum(grepl(\"電機\", mg$major)) # 電機相關科系\n",
    "Finanace <- sum(grepl(\"金融\", mg$major), grepl(\"財金\", mg$major)) # 財金相關科系\n",
    "Business <- sum(grepl(\"企管\", mg$major), grepl(\"企業管理\", mg$major), grepl(\"國際企業\", mg$major), grepl(\"國企\", mg$major), grepl(\"商\", mg$major)) # 商學, 管理相關科系\n",
    "Econ <- sum(grepl(\"經濟\", mg$major)) # 經濟相關科系\n",
    "Nursing <- sum(grepl(\"護理\", mg$major)) # 護理相關科系\n",
    "Mechanical <- sum(grepl(\"機械\", mg$major)) # 機械相關科系\n",
    "Computer <- sum(grepl(\"電腦\", mg$major)) # 電腦相關科系\n",
    "Medicine <- sum(grepl(\"醫\", mg$major)) # 醫學相關科系\n",
    "CS <- sum(grepl(\"資訊\", mg$major)) # 資訊相關科系\n",
    "majornames <- c(\"外文類\", \"電機類\", \"財金類\", \"商管類\", \"經濟類\", \"護理類\", \"機械類\", \"電腦類\", \"醫學類\", \"資訊類\")\n",
    "topmajor <- c(ForeignLanguages, EE, Finanace, Business, Econ, Nursing, Mechanical, Computer, Medicine, CS)\n",
    "topmajor <- data.frame(count = topmajor, major = majornames)\n",
    "topmajor <- topmajor[order(topmajor$count, decreasing = T),]\n",
    "rownames(topmajor) <- NULL\n",
    "topmajor <- topmajor %>% \n",
    "  mutate(perc = count / sum(count)) \n",
    "    \n",
    "ggplot(topmajor, aes(x = reorder(major, -perc), y = perc, fill = perc)) + \n",
    "  geom_bar(stat = \"identity\", width = 0.5) +\n",
    "  labs(x = \"major\", y = \"percentage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Southeast Asia customer analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target_index <- grepl(\"東南亞\", X1214$content)|grepl(\"泰國\", X1214$content)|grepl(\"越南\", X1214$content)|grepl(\"菲律賓\", X1214$content)|grepl(\"新加坡\", X1214$content)|grepl(\"馬來西亞\", X1214$content)|grepl(\"東南亞\", X1214$title)|grepl(\"泰國\", X1214$title)|grepl(\"越南\", X1214$title)|grepl(\"菲律賓\", X1214$title)|grepl(\"新加坡\", X1214$title)|grepl(\"馬來西亞\", X1214$title)\n",
    "target <- X1214[target_index,]\n",
    "\n",
    "target_sp <- strsplit(target$author, \"大學\")\n",
    "target_sp2 <- lapply(seq(length(target_sp)), function(i) strsplit(target_sp[[i]][2], \"/\"))\n",
    "\n",
    "target_school <- c()\n",
    "target_major <- c()\n",
    "target_gender <- c()\n",
    "for(i in seq(length(target_sp2))){\n",
    "  target_school[i] <- paste0(target_sp[[i]][1], \"大學\")\n",
    "  target_major[i] <- target_sp2[[i]][[1]][1]\n",
    "  target_gender[i] <- target_sp2[[i]][[1]][2]\n",
    "}\n",
    "target_major[target_major %in% \"\"] <- NA\n",
    "summary(factor(target_major))[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t_mg <- na.omit(data.frame(school = target_school, major = target_major, gender = target_gender, stringsAsFactors = F))\n",
    "t_res <- summary(factor(target_major))\n",
    "t_mgtop <- t_mg[t_mg$major %in% names(t_res[1:10]), ]\n",
    "\n",
    "ggplot(t_mgtop, aes(x =  reorder(major, major, function(x) -length(x)), fill = gender)) + \n",
    "  geom_bar(width = 0.5, position = \"stack\") +\n",
    "  labs(x = \"major\", y = \"count\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t_mgstrange <- t_mg[t_mg$major %in% c(\"民航研究所\", \"化妝品應用與管理系\", \"生命科學系\", \"國際企業管理學系\", \"會議展覽與國際行銷學位學程\"), ]\n",
    "unique(t_mgstrange)\n",
    "\n",
    "t_mgtop2 <- t_mg[t_mg$major %in% names(t_res[c(1,4,5,7,9,11:15)]), ]\n",
    "\n",
    "ggplot(t_mgtop2, aes(x =  reorder(major, major, function(x) -length(x)), fill = gender)) + \n",
    "  geom_bar(width = 0.5, position = \"stack\") +\n",
    "  labs(x = \"major\", y = \"count\")\n",
    "\n",
    "t_mg <- na.omit(data.frame(school = target_school, major = target_major, gender = target_gender, stringsAsFactors = F))\n",
    "t_Languages <- sum(grepl(\"英語\", t_mg$major), grepl(\"英文\", t_mg$major), grepl(\"英國語文\", t_mg$major), grepl(\"外文\", t_mg$major), grepl(\"外語\", t_mg$major), grepl(\"外國語文\", t_mg$major), grepl(\"華語文\", t_mg$major), grepl(\"越南語\", t_mg$major), grepl(\"中國文學\", t_mg$major), grepl(\"亞洲語言\", t_mg$major)) # 語言相關科系\n",
    "t_Marketing <- sum(grepl(\"行銷\", t_mg$major))-sum(grepl(\"會議展覽與國際行銷學位學程\", t_mg$major)) # 行銷相關科系\n",
    "t_Finanace <- sum(grepl(\"金融\", t_mg$major), grepl(\"財金\", t_mg$major)) # 財金相關科系\n",
    "t_Business <- sum(grepl(\"企管\", t_mg$major), grepl(\"企業管理\", t_mg$major), grepl(\"國際企業\", t_mg$major), grepl(\"國企\", t_mg$major), grepl(\"商\", t_mg$major), grepl(\"國際經營\", t_mg$major), grepl(\"Business\", t_mg$major)) - sum(grepl(\"國際企業管理學\", t_mg$major))# 商學, 管理相關科系\n",
    "t_Econ <- sum(grepl(\"經濟\", t_mg$major)) # 經濟相關科系\n",
    "t_Nursing <- sum(grepl(\"護理\", t_mg$major)) # 護理相關科系\n",
    "t_Mechanical <- sum(grepl(\"機械\", t_mg$major)) # 機械相關科系\n",
    "t_Design <- sum(grepl(\"設計\", t_mg$major)) # 設計相關科系\n",
    "t_Tour <- sum(grepl(\"飯店\", t_mg$major), grepl(\"休閒\", t_mg$major), grepl(\"酒店\", t_mg$major), grepl(\"餐旅\", t_mg$major), grepl(\"旅館\", t_mg$major)) # 觀光相關科系\n",
    "t_CS <- sum(grepl(\"資訊\", t_mg$major)) # 資訊相關科系\n",
    "majornames <- c(\"語文類\", \"行銷類\", \"財金類\", \"商管類\", \"經濟類\", \"護理類\", \"機械類\", \"設計類\", \"觀光類\", \"資訊類\")\n",
    "t_topmajor <- c(t_Languages, t_Marketing, t_Finanace, t_Business, t_Econ, t_Nursing, t_Mechanical, t_Design, t_Tour, t_CS)\n",
    "t_topmajor <- data.frame(count = t_topmajor, major = majornames)\n",
    "t_topmajor <- t_topmajor[order(t_topmajor$count, decreasing = T),]\n",
    "rownames(t_topmajor) <- NULL\n",
    "t_topmajor <- t_topmajor %>% \n",
    "  mutate(perc = count / sum(count)) \n",
    "    \n",
    "ggplot(t_topmajor, aes(x = reorder(major, -perc), y = perc, fill = perc)) + \n",
    "  geom_bar(stat = \"identity\", width = 0.5) +\n",
    "  labs(x = \"major\", y = \"percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### popular major analysis and major keyword analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sys.setlocale(category = \"LC_ALL\", locale = \"cht\")\n",
    "\n",
    "setwd(\"~/[R]/[DatabaseManagement]FinalProject\")\n",
    "\n",
    "library(readr)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(psych)\n",
    "library(jiebaR)\n",
    "library(wordcloud)\n",
    "library(lubridate)\n",
    "library(RODBC)\n",
    "\n",
    "options(repos = c(CRAN = \"0-cloud\"))\n",
    "c_abroad <- odbcConnect(dsn = 'DB_2019Abroad', uid='root', pwd='willy129897910', DBMSencoding=\"UTF-8\")\n",
    "\n",
    "\n",
    "jb <- worker()\n",
    "mix <- worker(\"mix\")\n",
    "tagger <- worker(\"tag\")\n",
    "\n",
    "############################################################################################\n",
    "# --- 10大熱門科系 --- by Jimmy\n",
    "# 將科系進行分類，最後整理出十大類(rule based)，分別為外文類, 電機類, 財金類, 商管類, 經濟類, 護理類, 機械類, 電腦類, 醫學類以及資訊類\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# 9. 找出各領域的關鍵字，希望可以用關鍵字來判斷你能適合哪些領域相關（這個領域適合哪些人）-- Willy\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "### 1. 外文類\n",
    "\n",
    "# 外文相關科系 --- language\n",
    "# \"英語\", \"英文\", \"英國語文\", \"外文\", \"外語\", \"外國語文\"\n",
    "\n",
    "pop_language_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%英語%\"\n",
    "                     or `author` like \"%英文%\"\n",
    "                     or `author` like \"%英國語文%\"\n",
    "                     or `author` like \"%外文%\"\n",
    "                     or `author` like \"%外語%\"\n",
    "                     or `author` like \"%外國語文%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_language <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%英語%\"\n",
    "                     or `author` like \"%英文%\"\n",
    "                     or `author` like \"%英國語文%\"\n",
    "                     or `author` like \"%外文%\"\n",
    "                     or `author` like \"%外語%\"\n",
    "                     or `author` like \"%外國語文%\");')\n",
    "content_language <- as.data.frame(table(segment(toString(pop_language$content) , mix)))\n",
    "colnames(content_language) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_language)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_language$word[i]))\n",
    "}\n",
    "content_language <- cbind(content_language, wordtype)\n",
    "colnames(content_language) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_language_n <- rbind(subset(content_language, type == \"n\"), \n",
    "                           subset(content_language, type == \"ns\"), \n",
    "                           subset(content_language, type == \"nt\"), \n",
    "                           subset(content_language, type == \"nrt\"), \n",
    "                           subset(content_language, type == \"j\"), \n",
    "                           subset(content_language, type == \"nrfg\"), \n",
    "                           subset(content_language, type == \"an\"), \n",
    "                           subset(content_language, type == \"vn\"))\n",
    "content_language_n <- subset(content_language_n, content_language_n$word != \"人\"& \n",
    "                              content_language_n$word != \"大家\"&\n",
    "                              content_language_n$word != \"我會\"&\n",
    "                              content_language_n$word != \"時候\"&\n",
    "                              content_language_n$word != \"原\"&\n",
    "                              content_language_n$word != \"基本上\"&\n",
    "                              content_language_n$word != \"東西\"&\n",
    "                              content_language_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_language_n$word,\n",
    "  content_language_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_language_adj <- rbind(subset(content_language, type == \"a\"), \n",
    "                             subset(content_language, type == \"ag\"), \n",
    "                             subset(content_language, type == \"ad\"), \n",
    "                             subset(content_language, type == \"an\"))\n",
    "content_language_adj <- subset(content_language_adj, content_language_adj$word != \"好\"&\n",
    "                                content_language_adj$word != \"直接\"&\n",
    "                                content_language_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_language_adj$word,\n",
    "  content_language_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 2. 電機類 --- engineer\n",
    "\n",
    "# 電機相關科系\n",
    "# \"電機\"\n",
    "pop_engineer_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%電機%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_engineer <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where (`author` like \"%電機%\");')\n",
    "content_engineer <- as.data.frame(table(segment(toString(pop_engineer$content) , mix)))\n",
    "colnames(content_engineer) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_engineer)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_engineer$word[i]))\n",
    "}\n",
    "content_engineer <- cbind(content_engineer, wordtype)\n",
    "colnames(content_engineer) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_engineer_n <- rbind(subset(content_engineer, type == \"n\"), \n",
    "                           subset(content_engineer, type == \"ns\"), \n",
    "                           subset(content_engineer, type == \"nt\"), \n",
    "                           subset(content_engineer, type == \"nrt\"), \n",
    "                           subset(content_engineer, type == \"j\"), \n",
    "                           subset(content_engineer, type == \"nrfg\"), \n",
    "                           subset(content_engineer, type == \"an\"), \n",
    "                           subset(content_engineer, type == \"vn\"))\n",
    "content_engineer_n <- subset(content_engineer_n, content_engineer_n$word != \"人\"& \n",
    "                              content_engineer_n$word != \"大家\"&\n",
    "                              content_engineer_n$word != \"我會\"&\n",
    "                              content_engineer_n$word != \"時候\"&\n",
    "                              content_engineer_n$word != \"原\"&\n",
    "                              content_engineer_n$word != \"基本上\"&\n",
    "                              content_engineer_n$word != \"東西\"&\n",
    "                              content_engineer_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_engineer_n$word,\n",
    "  content_engineer_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_engineer_adj <- rbind(subset(content_engineer, type == \"a\"), \n",
    "                             subset(content_engineer, type == \"ag\"), \n",
    "                             subset(content_engineer, type == \"ad\"), \n",
    "                             subset(content_engineer, type == \"an\"))\n",
    "content_engineer_adj <- subset(content_engineer_adj, content_engineer_adj$word != \"好\"&\n",
    "                                content_engineer_adj$word != \"直接\"&\n",
    "                                content_engineer_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_engineer_adj$word,\n",
    "  content_engineer_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 3. 財金類 --- finance\n",
    "\n",
    "# 財金相關科系\n",
    "# \"財金\", \"財務\"\n",
    "\n",
    "pop_finance_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%財金%\"\n",
    "                     or `author` like \"%財務%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_finance <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%財金%\"\n",
    "                     or `author` like \"%財務%\");')\n",
    "content_finance <- as.data.frame(table(segment(toString(pop_finance$content) , mix)))\n",
    "colnames(content_finance) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_finance)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_finance$word[i]))\n",
    "}\n",
    "content_finance <- cbind(content_finance, wordtype)\n",
    "colnames(content_finance) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_finance_n <- rbind(subset(content_finance, type == \"n\"), \n",
    "                              subset(content_finance, type == \"ns\"), \n",
    "                              subset(content_finance, type == \"nt\"), \n",
    "                              subset(content_finance, type == \"nrt\"), \n",
    "                              subset(content_finance, type == \"j\"), \n",
    "                              subset(content_finance, type == \"nrfg\"), \n",
    "                              subset(content_finance, type == \"an\"), \n",
    "                              subset(content_finance, type == \"vn\"))\n",
    "content_finance_n <- subset(content_finance_n, content_finance_n$word != \"人\"& \n",
    "                                 content_finance_n$word != \"大家\"&\n",
    "                                 content_finance_n$word != \"我會\"&\n",
    "                                 content_finance_n$word != \"時候\"&\n",
    "                                 content_finance_n$word != \"原\"&\n",
    "                                 content_finance_n$word != \"基本上\"&\n",
    "                                 content_finance_n$word != \"東西\"&\n",
    "                                 content_finance_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_finance_n$word,\n",
    "  content_finance_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_finance_adj <- rbind(subset(content_finance, type == \"a\"), \n",
    "                                subset(content_finance, type == \"ag\"), \n",
    "                                subset(content_finance, type == \"ad\"), \n",
    "                                subset(content_finance, type == \"an\"))\n",
    "content_finance_adj <- subset(content_finance_adj, content_finance_adj$word != \"好\"&\n",
    "                                   content_finance_adj$word != \"直接\"&\n",
    "                                   content_finance_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_finance_adj$word,\n",
    "  content_finance_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 4. 商管類 --- management\n",
    "\n",
    "# 商學, 管理相關科系\n",
    "# \"企管\", \"企業管理\", \"國際企業\", \"國企\", \"商\"\n",
    "pop_management_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%企管%\"\n",
    "                     or `author` like \"%企業管理%\"\n",
    "                     or `author` like \"%國際企業%\"\n",
    "                     or `author` like \"%國企%\"\n",
    "                     or `author` like \"%商%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_management <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%企管%\"\n",
    "                     or `author` like \"%企業管理%\"\n",
    "                     or `author` like \"%國際企業%\"\n",
    "                     or `author` like \"%國企%\"\n",
    "                     or `author` like \"%商%\");')\n",
    "content_management <- as.data.frame(table(segment(toString(pop_management$content) , mix)))\n",
    "colnames(content_management) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_management)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_management$word[i]))\n",
    "}\n",
    "content_management <- cbind(content_management, wordtype)\n",
    "colnames(content_management) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_management_n <- rbind(subset(content_management, type == \"n\"), \n",
    "                           subset(content_management, type == \"ns\"), \n",
    "                           subset(content_management, type == \"nt\"), \n",
    "                           subset(content_management, type == \"nrt\"), \n",
    "                           subset(content_management, type == \"j\"), \n",
    "                           subset(content_management, type == \"nrfg\"), \n",
    "                           subset(content_management, type == \"an\"), \n",
    "                           subset(content_management, type == \"vn\"))\n",
    "content_management_n <- subset(content_management_n, content_management_n$word != \"人\"& \n",
    "                              content_management_n$word != \"大家\"&\n",
    "                              content_management_n$word != \"我會\"&\n",
    "                              content_management_n$word != \"時候\"&\n",
    "                              content_management_n$word != \"原\"&\n",
    "                              content_management_n$word != \"基本上\"&\n",
    "                              content_management_n$word != \"東西\"&\n",
    "                              content_management_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_management_n$word,\n",
    "  content_management_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_management_adj <- rbind(subset(content_management, type == \"a\"), \n",
    "                             subset(content_management, type == \"ag\"), \n",
    "                             subset(content_management, type == \"ad\"), \n",
    "                             subset(content_management, type == \"an\"))\n",
    "content_management_adj <- subset(content_management_adj, content_management_adj$word != \"好\"&\n",
    "                                content_management_adj$word != \"直接\"&\n",
    "                                content_management_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_management_adj$word,\n",
    "  content_management_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "### 5. 經濟類 --- economics\n",
    "\n",
    "# \"經濟\" # 經濟相關科系\n",
    "pop_economics_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%經濟%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_economics <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%經濟%\");')\n",
    "content_economics <- as.data.frame(table(segment(toString(pop_economics$content) , mix)))\n",
    "colnames(content_economics) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_economics)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_economics$word[i]))\n",
    "}\n",
    "content_economics <- cbind(content_economics, wordtype)\n",
    "colnames(content_economics) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_economics_n <- rbind(subset(content_economics, type == \"n\"), \n",
    "                              subset(content_economics, type == \"ns\"), \n",
    "                              subset(content_economics, type == \"nt\"), \n",
    "                              subset(content_economics, type == \"nrt\"), \n",
    "                              subset(content_economics, type == \"j\"), \n",
    "                              subset(content_economics, type == \"nrfg\"), \n",
    "                              subset(content_economics, type == \"an\"), \n",
    "                              subset(content_economics, type == \"vn\"))\n",
    "content_economics_n <- subset(content_economics_n, content_economics_n$word != \"人\"& \n",
    "                                 content_economics_n$word != \"大家\"&\n",
    "                                 content_economics_n$word != \"我會\"&\n",
    "                                 content_economics_n$word != \"時候\"&\n",
    "                                 content_economics_n$word != \"原\"&\n",
    "                                 content_economics_n$word != \"基本上\"&\n",
    "                                 content_economics_n$word != \"東西\"&\n",
    "                                 content_economics_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_economics_n$word,\n",
    "  content_economics_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_economics_adj <- rbind(subset(content_economics, type == \"a\"), \n",
    "                                subset(content_economics, type == \"ag\"), \n",
    "                                subset(content_economics, type == \"ad\"), \n",
    "                                subset(content_economics, type == \"an\"))\n",
    "content_economics_adj <- subset(content_economics_adj, content_economics_adj$word != \"好\"&\n",
    "                                   content_economics_adj$word != \"直接\"&\n",
    "                                   content_economics_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_economics_adj$word,\n",
    "  content_economics_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 6. 護理類 --- nursing\n",
    "# \"護理\" # 護理相關科系\n",
    "\n",
    "pop_nursing_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%護理%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_nursing <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%護理%\");')\n",
    "content_nursing <- as.data.frame(table(segment(toString(pop_nursing$content) , mix)))\n",
    "colnames(content_nursing) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_nursing)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_nursing$word[i]))\n",
    "}\n",
    "content_nursing <- cbind(content_nursing, wordtype)\n",
    "colnames(content_nursing) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_nursing_n <- rbind(subset(content_nursing, type == \"n\"), \n",
    "                              subset(content_nursing, type == \"ns\"), \n",
    "                              subset(content_nursing, type == \"nt\"), \n",
    "                              subset(content_nursing, type == \"nrt\"), \n",
    "                              subset(content_nursing, type == \"j\"), \n",
    "                              subset(content_nursing, type == \"nrfg\"), \n",
    "                              subset(content_nursing, type == \"an\"), \n",
    "                              subset(content_nursing, type == \"vn\"))\n",
    "content_nursing_n <- subset(content_nursing_n, content_nursing_n$word != \"人\"& \n",
    "                                 content_nursing_n$word != \"大家\"&\n",
    "                                 content_nursing_n$word != \"我會\"&\n",
    "                                 content_nursing_n$word != \"時候\"&\n",
    "                                 content_nursing_n$word != \"原\"&\n",
    "                                 content_nursing_n$word != \"基本上\"&\n",
    "                                 content_nursing_n$word != \"東西\"&\n",
    "                                 content_nursing_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_nursing_n$word,\n",
    "  content_nursing_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_nursing_adj <- rbind(subset(content_nursing, type == \"a\"), \n",
    "                                subset(content_nursing, type == \"ag\"), \n",
    "                                subset(content_nursing, type == \"ad\"), \n",
    "                                subset(content_nursing, type == \"an\"))\n",
    "content_nursing_adj <- subset(content_nursing_adj, content_nursing_adj$word != \"好\"&\n",
    "                                   content_nursing_adj$word != \"直接\"&\n",
    "                                   content_nursing_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_nursing_adj$word,\n",
    "  content_nursing_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 7. 機械類 --- mechanics\n",
    "# \"機械\" # 機械相關科系\n",
    "\n",
    "pop_mechanics_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%機械%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_mechanics <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%機械%\");')\n",
    "content_mechanics <- as.data.frame(table(segment(toString(pop_mechanics$content) , mix)))\n",
    "colnames(content_mechanics) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_mechanics)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_mechanics$word[i]))\n",
    "}\n",
    "content_mechanics <- cbind(content_mechanics, wordtype)\n",
    "colnames(content_mechanics) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_mechanics_n <- rbind(subset(content_mechanics, type == \"n\"), \n",
    "                              subset(content_mechanics, type == \"ns\"), \n",
    "                              subset(content_mechanics, type == \"nt\"), \n",
    "                              subset(content_mechanics, type == \"nrt\"), \n",
    "                              subset(content_mechanics, type == \"j\"), \n",
    "                              subset(content_mechanics, type == \"nrfg\"), \n",
    "                              subset(content_mechanics, type == \"an\"), \n",
    "                              subset(content_mechanics, type == \"vn\"))\n",
    "content_mechanics_n <- subset(content_mechanics_n, content_mechanics_n$word != \"人\"& \n",
    "                                 content_mechanics_n$word != \"大家\"&\n",
    "                                 content_mechanics_n$word != \"我會\"&\n",
    "                                 content_mechanics_n$word != \"時候\"&\n",
    "                                 content_mechanics_n$word != \"原\"&\n",
    "                                 content_mechanics_n$word != \"基本上\"&\n",
    "                                 content_mechanics_n$word != \"東西\"&\n",
    "                                 content_mechanics_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_mechanics_n$word,\n",
    "  content_mechanics_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_mechanics_adj <- rbind(subset(content_mechanics, type == \"a\"), \n",
    "                                subset(content_mechanics, type == \"ag\"), \n",
    "                                subset(content_mechanics, type == \"ad\"), \n",
    "                                subset(content_mechanics, type == \"an\"))\n",
    "content_mechanics_adj <- subset(content_mechanics_adj, content_mechanics_adj$word != \"好\"&\n",
    "                                   content_mechanics_adj$word != \"直接\"&\n",
    "                                   content_mechanics_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_mechanics_adj$word,\n",
    "  content_mechanics_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 8. 電腦類 --- computerscience\n",
    "# \"電腦\" # 電腦相關科系\n",
    "\n",
    "pop_computerscience_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%電腦%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_computerscience <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%電腦%\");')\n",
    "content_computerscience <- as.data.frame(table(segment(toString(pop_computerscience$content) , mix)))\n",
    "colnames(content_computerscience) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_computerscience)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_computerscience$word[i]))\n",
    "}\n",
    "content_computerscience <- cbind(content_computerscience, wordtype)\n",
    "colnames(content_computerscience) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_computerscience_n <- rbind(subset(content_computerscience, type == \"n\"), \n",
    "                              subset(content_computerscience, type == \"ns\"), \n",
    "                              subset(content_computerscience, type == \"nt\"), \n",
    "                              subset(content_computerscience, type == \"nrt\"), \n",
    "                              subset(content_computerscience, type == \"j\"), \n",
    "                              subset(content_computerscience, type == \"nrfg\"), \n",
    "                              subset(content_computerscience, type == \"an\"), \n",
    "                              subset(content_computerscience, type == \"vn\"))\n",
    "content_computerscience_n <- subset(content_computerscience_n, content_computerscience_n$word != \"人\"& \n",
    "                                 content_computerscience_n$word != \"大家\"&\n",
    "                                 content_computerscience_n$word != \"我會\"&\n",
    "                                 content_computerscience_n$word != \"時候\"&\n",
    "                                 content_computerscience_n$word != \"原\"&\n",
    "                                 content_computerscience_n$word != \"基本上\"&\n",
    "                                 content_computerscience_n$word != \"東西\"&\n",
    "                                 content_computerscience_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_computerscience_n$word,\n",
    "  content_computerscience_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_computerscience_adj <- rbind(subset(content_computerscience, type == \"a\"), \n",
    "                                subset(content_computerscience, type == \"ag\"), \n",
    "                                subset(content_computerscience, type == \"ad\"), \n",
    "                                subset(content_computerscience, type == \"an\"))\n",
    "content_computerscience_adj <- subset(content_computerscience_adj, content_computerscience_adj$word != \"好\"&\n",
    "                                   content_computerscience_adj$word != \"直接\"&\n",
    "                                   content_computerscience_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_computerscience_adj$word,\n",
    "  content_computerscience_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n",
    "\n",
    "### 10. 資訊類 --information\n",
    "# \"資訊\"# 資訊相關科系\n",
    "\n",
    "pop_information_score <- sqlQuery(c_abroad, 'select (avg(`postive_score`) - avg(`negative_score`)) as score\n",
    "                    from `abroad`\n",
    "                    where \n",
    "                    (`author` like \"%資訊%\")\n",
    "                     and `postive_score` > 0\n",
    "                     and `negative_score` > 0 ;')\n",
    "pop_information <- sqlQuery(c_abroad, 'select `content_type`,`author`, `title`, `content`, `negative_score`, `postive_score`, `pos` \n",
    "                    from `abroad`\n",
    "                    where (`author` like \"%資訊%\");')\n",
    "content_information <- as.data.frame(table(segment(toString(pop_information$content) , mix)))\n",
    "colnames(content_information) <- c('word', 'cnt')\n",
    "\n",
    "wordtype <- c()\n",
    "for (i in 1:nrow(content_information)) {\n",
    "  wordtype[i] = names(tagger <= toString(content_information$word[i]))\n",
    "}\n",
    "content_information <- cbind(content_information, wordtype)\n",
    "colnames(content_information) <- c('word', 'cnt', 'type')\n",
    "\n",
    "# N.\n",
    "content_information_n <- rbind(subset(content_information, type == \"n\"), \n",
    "                              subset(content_information, type == \"ns\"), \n",
    "                              subset(content_information, type == \"nt\"), \n",
    "                              subset(content_information, type == \"nrt\"), \n",
    "                              subset(content_information, type == \"j\"), \n",
    "                              subset(content_information, type == \"nrfg\"), \n",
    "                              subset(content_information, type == \"an\"), \n",
    "                              subset(content_information, type == \"vn\"))\n",
    "content_information_n <- subset(content_information_n, content_information_n$word != \"人\"& \n",
    "                                 content_information_n$word != \"大家\"&\n",
    "                                 content_information_n$word != \"我會\"&\n",
    "                                 content_information_n$word != \"時候\"&\n",
    "                                 content_information_n$word != \"原\"&\n",
    "                                 content_information_n$word != \"基本上\"&\n",
    "                                 content_information_n$word != \"東西\"&\n",
    "                                 content_information_n$word != \"問題\")\n",
    "\n",
    "wordcloud(\n",
    "  content_information_n$word,\n",
    "  content_information_n$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\"),\n",
    ")\n",
    "\n",
    "# Adj.\n",
    "content_information_adj <- rbind(subset(content_information, type == \"a\"), \n",
    "                                subset(content_information, type == \"ag\"), \n",
    "                                subset(content_information, type == \"ad\"), \n",
    "                                subset(content_information, type == \"an\"))\n",
    "content_information_adj <- subset(content_information_adj, content_information_adj$word != \"好\"&\n",
    "                                   content_information_adj$word != \"直接\"&\n",
    "                                   content_information_adj$word != \"大\")\n",
    "wordcloud(\n",
    "  content_information_adj$word,\n",
    "  content_information_adj$cnt,\n",
    "  max.words = 100,\n",
    "  scale = c(2.5, 1),\n",
    "  colors = brewer.pal(8, \"Paired\")\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
